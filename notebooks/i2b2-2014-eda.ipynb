{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from collections import defaultdict, Counter\n",
    "from presidio_evaluator import InputSample\n",
    "from presidio_evaluator.evaluation import ModelError, Evaluator\n",
    "from presidio_evaluator.dataset_formatters import I2B22014Formatter\n",
    "from presidio_evaluator.models import PresidioAnalyzerWrapper\n",
    "\n",
    "from presidio_analyzer import AnalyzerEngine\n",
    "from presidio_analyzer.nlp_engine import NlpEngine, NlpEngineProvider"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Presidio on the I2B2-2014 de-identification dataset\n",
    "\n",
    "#### Prerequisites:\n",
    "1. Get access to the data\n",
    "2. Copy the data to the `/data/i2b2/2014` folder on the top of the repo. You should have three folders:\n",
    "    - `testing-PHI-Gold-fixed`\n",
    "    - `training-PHI-Gold-Set1`\n",
    "    - `training-PHI-Gold-Set2`\n",
    "3. Run the following cell for creating a list of InputSamples and save them to json:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%% raw\n"
    }
   },
   "outputs": [],
   "source": [
    "CREATE_DATASET=False #Change to true on the first run\n",
    "\n",
    "\n",
    "if CREATE_DATASET:\n",
    "    # Data is assumed to be on the data folder (repo root) under i2b2/2014\n",
    "    # train 1\n",
    "    input_path1 = Path(\"../data/i2b2/2014/training-PHI-Gold-Set1\")\n",
    "    output_path1 = Path(\"../data/i2b2/2014/training-PHI-Gold-Set1.json\")\n",
    "    I2B22014Formatter.dataset_to_json(input_path1, output_path1)\n",
    "\n",
    "    # train 2\n",
    "    input_path2 = Path(\"../data/i2b2/2014/training-PHI-Gold-Set2\")\n",
    "    output_path2 = Path(\"../data/i2b2/2014/training-PHI-Gold-Set2.json\")\n",
    "    I2B22014Formatter.dataset_to_json(input_path2, output_path2)\n",
    "\n",
    "    # test\n",
    "    input_path3 = Path(\"../data/i2b2/2014/testing-PHI-Gold-fixed\")\n",
    "    output_path3 = Path(\"../data/i2b2/2014/testing-PHI-Gold-fixed.json\")\n",
    "    I2B22014Formatter.dataset_to_json(input_path3, output_path3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def read_json_dataset(filepath=None, length=None):\n",
    "\n",
    "    with open(filepath, \"r\", encoding=\"utf-8\") as f:\n",
    "        dataset = json.load(f)\n",
    "\n",
    "    if length:\n",
    "        dataset = dataset[:length]\n",
    "\n",
    "    input_samples = [InputSample.from_json(row) for row in dataset]\n",
    "\n",
    "    return input_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dataset = read_json_dataset(\"../data/i2b2/2014/testing-PHI-Gold-fixed.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% raw\n"
    }
   },
   "source": [
    "Entity types in this dataset and their frequencies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "flatten = lambda l: [item for sublist in l for item in sublist]\n",
    "count_per_entity = Counter([span.entity_type for span in flatten([input_sample.spans for input_sample in dataset])])\n",
    "count_per_entity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% raw\n"
    }
   },
   "source": [
    "Translate I2b2 2014 entity types to Presidio's (If available)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "i2b2_presidio_dict = {\n",
    "    \"PATIENT\": \"PERSON\",\n",
    "    \"DOCTOR\": \"PERSON\",\n",
    "    \"AGE\":\"AGE\", # Not supported in Presidio\n",
    "    \"BIOID\": \"BIOID\", # Not supported in Presidio\n",
    "    \"COUNTRY\": \"LOCATION\",\n",
    "    \"CITY\":\"LOCATION\",\n",
    "    \"DATE\": \"DATE_TIME\",\n",
    "    \"DEVICE\": \"DEVICE\", # Not supported in Presidio\n",
    "    \"EMAIL\": \"EMAIL_ADDRESS\",\n",
    "    \"FAX\": \"US_PHONE_NUMBER\",\n",
    "    \"HEALTHPLAN\": \"HEALTHPLAN\", # Not supported in Presidio\n",
    "    \"HOSPITAL\": \"ORGANIZATION\",\n",
    "    \"IDNUM\": \"IDNUM\", # Not supported in Presidio\n",
    "    \"LOCATION-OTHER\": \"LOCATION\",\n",
    "    \"MEDICALRECORD\": \"MEDICAL_RECORD\", # Not supported in Presidio\n",
    "    \"ORGANIZATION\": \"ORGANIZATION\",\n",
    "    \"PHONE\": \"PHONE_NUMBER\",\n",
    "    \"PROFESSION\": \"PROFESSION\", # Not supported in Presidio\n",
    "    \"STATE\": \"LOCATION\",\n",
    "    \"STREET\": \"LOCATION\",\n",
    "    \"URL\": \"DOMAIN_NAME\",\n",
    "    \"USERNAME\": \"USERNAME\", # Not supported in Presidio\n",
    "    \"ZIP\": \"ZIP\", # Not supported in Presidio\n",
    "    \"O\": \"O\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "Examine different entity values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "values_per_entity = defaultdict(set)\n",
    "for sample in dataset:\n",
    "    for span in sample.spans:\n",
    "        values_per_entity[span.entity_type].add(span.entity_value)\n",
    "\n",
    "values_per_entity['ORGANIZATION']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "new_dataset = Evaluator.align_entity_types(input_samples=dataset, entities_mapping=i2b2_presidio_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Re-calculate frequency per entity_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "count_per_entity_new = Counter([span.entity_type for span in flatten([input_sample.spans for input_sample in new_dataset])])\n",
    "count_per_entity_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Set up analyzer\n",
    "analyzer = AnalyzerEngine()\n",
    "\n",
    "\n",
    "# Run evaluation\n",
    "presidio = PresidioAnalyzerWrapper(analyzer_engine=analyzer,\n",
    "                                   entities_to_keep=list(count_per_entity_new.keys()))\n",
    "evaluator = Evaluator(model=presidio)\n",
    "evaluated = evaluator.evaluate_all(new_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "evaluation_result = evaluator.calculate_score(evaluated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_result.print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyze wrong predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = evaluation_result.model_errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "False positives analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ModelError.most_common_fp_tokens(errors,n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ModelError.get_fps_dataframe(errors,entity='PERSON')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "False negatives analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ModelError.most_common_fn_tokens(errors,n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ModelError.get_fns_dataframe(errors,entity='PERSON')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "presidio-research",
   "language": "python",
   "name": "presidio-research"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
